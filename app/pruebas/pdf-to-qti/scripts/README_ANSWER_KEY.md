# Gu√≠a: Integraci√≥n de Respuestas Correctas

Este documento explica c√≥mo integrar las respuestas correctas de un PDF al proceso de generaci√≥n QTI.

## üìã Proceso Completo

### Paso 1: Subir PDF con Respuestas Correctas

Coloca el PDF con las respuestas correctas en la carpeta de la prueba:
```
app/data/pruebas/raw/{test-name}/respuestas-{nombre-prueba}.pdf
```

Por ejemplo:
```
app/data/pruebas/raw/prueba-invierno-2026/respuestas-prueba-invierno-2026.pdf
```

O si el archivo tiene otro nombre (como un clavijero):
```
app/data/pruebas/raw/prueba-invierno-2026/2026-25-07-18-clavijero-paes-invierno-m1.pdf
```

**Estructura de carpetas:**
```
app/data/pruebas/raw/
  ‚îî‚îÄ‚îÄ prueba-invierno-2026/
      ‚îú‚îÄ‚îÄ prueba-invierno-2026.pdf        # PDF de la prueba
      ‚îî‚îÄ‚îÄ respuestas-prueba-invierno-2026.pdf  # PDF con respuestas (o cualquier nombre)
```

### Paso 2: Extraer Respuestas del PDF

Ejecuta el script de extracci√≥n:

```bash
cd app/pruebas/pdf-to-qti

python scripts/extract_answer_key.py \
    --pdf-path ../../data/pruebas/raw/prueba-invierno-2026/respuestas-prueba-invierno-2026.pdf \
    --output ../../data/pruebas/procesadas/prueba-invierno-2026/respuestas_correctas.json \
    --test-name prueba-invierno-2026 \
    --focus-page 3
```

Si las respuestas est√°n en una p√°gina espec√≠fica (por ejemplo, p√°gina 3), usa `--focus-page 3` para que el script se enfoque solo en esa p√°gina.

Este script:
- Extrae el texto del PDF
- Usa AI para identificar las respuestas correctas
- Genera un JSON con el mapeo pregunta ‚Üí respuesta
- Guarda el resultado en la ubicaci√≥n especificada

### Paso 3: Procesar Preguntas con Respuestas

Cuando proceses las preguntas, el pipeline detectar√° autom√°ticamente el archivo `respuestas_correctas.json` y usar√° las respuestas correctas al generar el QTI.

```bash
# El pipeline buscar√° autom√°ticamente el archivo de respuestas
python process_paes_invierno.py --paes-mode
```

## üìÅ Estructura del JSON de Respuestas

El archivo `respuestas_correctas.json` tiene esta estructura:

```json
{
  "test_name": "prueba-invierno-2026",
  "source_pdf": "app/data/pruebas/raw/prueba-invierno-2026/respuestas-prueba-invierno-2026.pdf",
  "total_questions": 65,
  "answers": {
    "1": "ChoiceA",
    "2": "ChoiceB",
    "3": "ChoiceD",
    "4": "ChoiceC",
    ...
    "65": "ChoiceA"
  },
  "metadata": {
    "extraction_method": "AI (Gemini/OpenAI)",
    "question_numbers": ["1", "2", "3", ..., "65"]
  }
}
```

**Formato de respuestas:**
- Las claves son n√∫meros de pregunta como strings: `"1"`, `"2"`, etc.
- Los valores son identificadores QTI: `"ChoiceA"`, `"ChoiceB"`, `"ChoiceC"`, `"ChoiceD"`

## üîç C√≥mo Funciona

1. **Extracci√≥n**: El script `extract_answer_key.py` usa AI para identificar respuestas correctas en el PDF
2. **Detecci√≥n autom√°tica**: El pipeline busca `respuestas_correctas.json` en el directorio de la prueba
3. **Integraci√≥n**: Las respuestas se pasan al prompt del LLM que genera el QTI
4. **Inclusi√≥n en XML**: El LLM incluye la respuesta correcta en `<qti-correct-response>`

## üìç Ubicaci√≥n del Archivo de Respuestas

El pipeline busca el archivo en estas ubicaciones (en orden):

1. `app/data/pruebas/procesadas/{test_name}/respuestas_correctas.json`
2. El directorio padre del output si est√° en una estructura espec√≠fica

Aseg√∫rate de que el archivo est√© en la primera ubicaci√≥n para garantizar que se encuentre.

## ‚úÖ Verificaci√≥n

Despu√©s de procesar, verifica que las respuestas correctas est√°n en los XMLs:

```bash
# Verificar que una pregunta tiene la respuesta correcta
grep -A 2 "qti-correct-response" app/data/pruebas/procesadas/prueba-invierno-2026/qti/Q3.xml
```

Deber√≠as ver algo como:
```xml
<qti-correct-response>
  <qti-value>ChoiceD</qti-value>
</qti-correct-response>
```

## ‚ö†Ô∏è Notas Importantes

- Si no se encuentra el archivo de respuestas, el LLM intentar√° inferir la respuesta correcta del contenido (comportamiento anterior)
- Las respuestas deben estar en formato `ChoiceA`, `ChoiceB`, etc. (el script convierte autom√°ticamente de A, B, C, D)
- Si una pregunta no tiene respuesta en el JSON, se usar√° la inferencia del LLM
- El archivo de respuestas es opcional - el pipeline funciona sin √©l, pero es m√°s preciso con √©l
